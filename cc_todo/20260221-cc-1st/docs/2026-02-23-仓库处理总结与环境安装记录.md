# NeuroBridge 仓库处理总结与环境安装记录

**整理日期**：2026-02-23
**分析范围**：从 commit `0a7748b34e78ae3776d811f9129444ad3d6ad631`（"添加数据集下载说明"）往后的所有 git 提交记录，以及 `cc_todo/` 下的文档记录

---

## 一、总体概述

在 "添加数据集下载说明" commit 之后，项目共新增了 **17 个 commit**（全部发生在 2026-02-21 同一天），完整实现了从神经信号编码到图像重建的 NeuroBridge Pipeline。所有代码由 `Jp-17 <jpagkr@163.com>` 提交，大量工作协同 Claude Opus 4.6 完成（Co-Authored-By: Claude Opus 4.6）。

---

## 二、Git 提交记录逐条分析

### Commit 1：`67f6697` — 添加 POYO 代码分析和 NeuroBridge 项目执行计划文档
**时间**：2026-02-21 15:23

**做了什么：**
- 新增 `cc_todo/2026-02-21-poyo-代码分析.md`：对 neuro-galaxy/POYO（torch_brain）代码库的深度分析，包括 PerceiverIO 架构、CaPOYO 变体对连续 MUA 信号的处理方式、可复用组件清单
- 新增 `cc_todo/2026-02-21-neurobridge-项目分析与执行计划.md`：NeuroBridge 项目合理性审查（6 个关键问题及解决方案）、Phase 0–4 执行计划、RTX 4090 24GB 资源约束下的架构决策（dim=128, depth=6，模型从 100M 缩减到 2.3M 参数）

---

### Commit 2：`fd297fd` — 更新进度日志（POYO 基线结果 + TVSD 数据探索）
**时间**：2026-02-21 16:16

**做了什么：**
- 更新执行计划文档，记录 POYO Baseline 训练完成（1000 epochs，R²=0.836）
- 记录 TVSD normMUA 数据集下载完成并探索结构：
  - monkeyF：V1（通道 1–512），IT（513–832），V4（833–1024）
  - monkeyN：V1（通道 1–512），V4（513–768），IT（769–1024）
  - 22248 训练样本 + 100 测试样本，对应 THINGS 图像

---

### Commit 3：`748a83d` — 实现 Phase 1a：TVSD 数据适配器 + NeuroBridge 编码器
**时间**：2026-02-21 16:34

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `neurobridge/__init__.py` | 包入口 |
| `neurobridge/data/__init__.py` | data 包入口 |
| `neurobridge/data/tvsd_dataset.py` | TVSD normMUA 数据集适配器（支持 raw/capoyo 模式、脑区过滤、SNR 过滤） |
| `neurobridge/models/__init__.py` | models 包入口 |
| `neurobridge/models/neurobridge_encoder.py` | CaPOYO 架构神经编码器（1024 MUA tokens → 8 latent tokens → 128-dim，2.3M 参数） |
| `neurobridge/tests/__init__.py` | 测试包入口 |
| `neurobridge/tests/test_tvsd_forward.py` | 5 项前向传播测试（数据集加载、tokenization、CPU/GPU 前向、批量 AMP） |

**验证结果：** 5/5 测试通过，GO/NO-GO 决策点 1：通过

---

### Commit 4：`25776f9` — 实现 Phase 2a：CLIP 对齐模块 + 训练管线
**时间**：2026-02-21 16:45

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `neurobridge/alignment/__init__.py` | alignment 包入口 |
| `neurobridge/alignment/clip_wrapper.py` | CLIP 模型包装器（open_clip ViT-L-14，768-dim） |
| `neurobridge/alignment/readout.py` | 可学习 Cross-Attention Readout（K=8 查询向量） |
| `neurobridge/alignment/projector.py` | 3 层 MLP 投影器（→ CLIP 空间 768-dim） |
| `neurobridge/alignment/infonce.py` | 对称 InfoNCE 对比损失 |
| `scripts/train_clip_alignment.py` | CLIP 对齐端到端训练脚本 |

**验证结果：** Pipeline 随机 CLIP 嵌入验证通过，3.3M 参数，RTX 4090 约 7s/epoch

---

### Commit 5：`439b0de` — 添加 CLIP 嵌入提取脚本
**时间**：2026-02-21 16:58

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `scripts/extract_clip_embeddings.py` | 从 THINGS 图像提取 ViT-L-14 CLIP 嵌入，保存为 .npy 文件 |

---

### Commit 6：`c089711` — 添加 CLIP 对齐评估脚本
**时间**：2026-02-21 17:00

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `scripts/evaluate_alignment.py` | 检索准确率评估（Top-1/5/10/50，双向，中位/均值排名，相似度分布分析） |

---

### Commit 7：`02236d5` — 实现 Phase 2c：Diffusion Adapter + SD 包装器
**时间**：2026-02-21 17:01

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `neurobridge/generation/__init__.py` | generation 包入口 |
| `neurobridge/generation/diffusion_adapter.py` | DiffusionAdapter（将 768-dim CLIP 嵌入��开为 77-token SD Prompt Sequence）+ StableDiffusionWrapper（使用 Stable Diffusion 2.1 DDIM 采样生成图像） |

**架构：** 神经 CLIP 嵌入 (768-dim) → DiffusionAdapter → (77, 1024) → SD → 图像

---

### Commit 8：`33780c7` — 更新进度日志（Phase 2a-2c 模块完成，THINGS 图像下载中）
**时间**：2026-02-21 17:02

**做了什么：** 文档更新，记录所有核心模块已实现，THINGS 图像从 OSF 下载进行中（约 5GB）

---

### Commit 9：`cdbb231` — 更新进度日志（Phase 2b：CLIP 嵌入提取 + 训练启动）
**时间**：2026-02-21 17:46

**做了什么：**
- THINGS 图像下载完成（4.68GB，1854 类，0 缺失）
- CLIP 嵌入提取完成（ViT-L-14，22248 训练 + 100 测试）
- CLIP 对齐训练启动（100 epochs，batch=256，3.3M 参数）
- 更新 `.gitignore`，排除 checkpoints 和大型数据文件

---

### Commit 10：`1005358` — CLIP 对齐训练完成（Test Top-1=53%，Top-5=82%）
**时间**：2026-02-21 17:52

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `scripts/reconstruct_images.py` | 端到端 SD 生成 Pipeline（神经信号 → CLIP 嵌入 → SD 图像重建） |

**训练结果（V1，无数据增强）：**
- 最佳 epoch：第 40 epoch（val top5=56.0%）
- 测试集（100 张）：Top-1=53%，Top-5=82%，Top-10=94%
- 问题：第 35–40 epoch 后严重过拟合，需要正则化

---

### Commit 11：`1a62620` — 添加数据增强 + 切换至 SD 1.5 + 改进训练管线
**时间**：2026-02-21 20:20

**代码修改：**
- `scripts/train_clip_alignment.py`：添加电极 Dropout + 高斯噪声增强、Early Stopping 支持
- `neurobridge/generation/diffusion_adapter.py`：将 `sd_hidden_dim` 默认值更新为 768（适配 SD 1.5）
- `scripts/reconstruct_images.py`：从 SD 2.1（需授权）切换到 SD 1.5（runwayml/stable-diffusion-v1-5，可直接访问）

---

### Commit 12：`e2f0acf` — V2 训练结果 + 每日总结（Test Top-5 提升至 85–89%）
**时间**：2026-02-21 20:24

**训练结果（V2，含数据增强）：**
- Val top5：62.8%（较 V1 的 56.0% 提升）
- 测试集 n2i Top-5：85%，i2n Top-5：89%
- Early stopping 于第 72 epoch

---

### Commit 13：`003a120` — 添加 DiffusionAdapter 训练脚本 + 首次重建结果
**时间**：2026-02-21 20:34

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `scripts/train_diffusion_adapter.py` | DiffusionAdapter 训练脚本（自监督目标：嵌入保真度 cosine、token 多样性、对比损失） |

**新增结果文件（已忽略大型图像/npy 文件）：**
- `results/reconstruction_v2/all_metrics.json`
- `results/reconstruction_v2/retrieval_metrics.json`
- 更新 `.gitignore`：排除 `results/` 下的 `.png`、`.jpg`、`.npy` 文件

**首次重建结果（未训练 Adapter）：** PixCorr=0.149

---

### Commit 14：`aec765b` — 实现 Phase 1b：Masking 预训练模块
**时间**：2026-02-21 20:46

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `neurobridge/pretraining/__init__.py` | pretraining 包入口 |
| `neurobridge/pretraining/masking_strategy.py` | 电极随机 Masking 策略（可配置脑区平衡） |
| `neurobridge/pretraining/masking_decoder.py` | Cross-attention 解码器（330K 参数） |
| `neurobridge/pretraining/masking_pretraining.py` | Encoder + Decoder 完整预训练模型（2.6M 参数，含 Masked MSE Loss） |
| `scripts/train_masking_pretraining.py` | 预训练训练脚本（Early Stopping + AMP） |

**训练结果：** 200 epochs，MSE 从 0.212 降至 0.092（降幅 56%）

---

### Commit 15：`4a1d42c` — 综合重建评估 + 检索基线
**时间**：2026-02-21 21:15

**新增代码文件：**
| 文件 | 内容 |
|------|------|
| `scripts/evaluate_reconstruction.py` | 重建评估脚本（PixCorr、CLIP 相似度、检索基线） |

**新增结果文件：**
- `results/reconstruction_v3_trained/all_metrics.json`
- `results/reconstruction_v3_trained/evaluation_metrics.json`
- `results/reconstruction_v3_trained/retrieval_metrics.json`

**评估结果（已训练 DiffusionAdapter，100 张测试图）：**

| 指标 | SD 生成 | 检索基线 |
|------|---------|---------|
| PixCorr | 0.036 | 0.125 |
| CLIP 相似度 | 0.606 | 0.677 |
| CLIP-ID Top-1 | 1% | 28% |
| 检索 Top-1 | 49% | — |
| 检索 Top-5 | 85% | — |

**结论：** 检索基线显著优于 SD 生成，SD 生成需要进一步改进

---

### Commit 16：`755fd63` — 添加预训练编码器支持 + Freeze Warmup
**时间**：2026-02-21 22:03

**代码修改：**
- `scripts/train_clip_alignment.py`：添加 `--pretrained_encoder` 参数（从 masking pretraining checkpoint 加载编码器）+ `--freeze_encoder_epochs` 参数（前 N epoch 冻结编码器进行 Warmup）

---

### Commit 17：`b77774d` — 完成 Phase 3 消融实验 + 综合结果
**时间**：2026-02-21 22:41

**代码修改：**
- `scripts/evaluate_alignment.py`：添加 `--regions` 参数支持（按脑区评估）

**消融实验结果：**

#### Phase 3a：预训练 vs 随机初始化
| 模型 | Top-1 | Top-5 |
|------|-------|-------|
| 随机初始化（直接训练） | 53% | 85% |
| Masking 预训练编码器 | — | 76% |

**结论：** 预训练编码器反而性能下降（76% < 85%），可能原因：预训练任务（MUA 重建）与下游任务（CLIP 对齐）目标不匹配

#### Phase 3b：脑区贡献分析
| 脑区 | 电极数 | Top-5 |
|------|--------|-------|
| IT（颞下皮层） | 320 | 77% |
| V4 | 192 | 58% |
| V1 | 512 | 45% |
| 全部（1024） | 1024 | 85% |

**结论：** IT 脑区信息量最大（符合神经科学认知），电极数不代表信息量（V1 电极最多但准确率最低）

---

## 三、仓库代码结构总结

经过所有 commit，`neurobridge/` 模块结构如��：

```
neurobridge/
├── __init__.py
├── data/
│   ├── __init__.py
│   └── tvsd_dataset.py          # TVSD normMUA 数据集适配器
├── models/
│   ├── __init__.py
│   └── neurobridge_encoder.py   # CaPOYO 神经编码器（2.3M 参数）
├── alignment/
│   ├── __init__.py
│   ├── clip_wrapper.py          # CLIP ViT-L-14 包装器
│   ├── readout.py               # Cross-Attention Readout
│   ├── projector.py             # MLP 投影器
│   └── infonce.py               # InfoNCE 对比损失
├── generation/
│   ├── __init__.py
│   └── diffusion_adapter.py     # DiffusionAdapter + SD 包装器（17.2M 参数）
├── pretraining/
│   ├── __init__.py
│   ├── masking_strategy.py      # 电极 Masking 策略
│   ├── masking_decoder.py       # Cross-Attention 解码器
│   └── masking_pretraining.py   # 完整预训练模型（2.6M 参数）
└── tests/
    └── test_tvsd_forward.py     # 前向传播验证测试

scripts/
├── extract_clip_embeddings.py   # CLIP 嵌入提取
├── train_clip_alignment.py      # CLIP 对齐训练
├── evaluate_alignment.py        # 检索准确率评估
├── train_masking_pretraining.py # Masking 预训练
├── train_diffusion_adapter.py   # DiffusionAdapter 训练
├── reconstruct_images.py        # 端到端图像重建
├── evaluate_reconstruction.py   # 重建质量评估
└── calculate_normalization_scales.py
```

---

## 四、下载/安装/运行的内容及位置

### 4.1 conda 环境

| 环境名 | 路径 | 用途 |
|--------|------|------|
| `poyo` | `miniconda3/envs/poyo/` | POYO 基线训练、NeuroBridge 主训练环境 |

**主要安装包：**
- PyTorch 2.10.0+cu128（含 CUDA 12.8）
- torch_brain 0.1.0（本地 editable 安装，源码在 `autodl-tmp/torch_brain/`）
- lightning 2.6.1
- torch-optimizer 0.3.0（包含 SparseLamb 优化器）
- brainsets 0.2.1.dev4+g073ac8ac5（从 GitHub 源安装，替换了有问题的 PyPI 版本 0.2.0）
- wandb 0.25.0
- open_clip（CLIP 嵌入提取）
- diffusers（Stable Diffusion）

---

### 4.2 代码库/框架

| 项目 | 来源 | 安装位置 |
|------|------|---------|
| torch_brain（POYO 源码） | neuro-galaxy/torch_brain GitHub | `autodl-tmp/torch_brain/`（本地 editable） |
| NeuroBridge（本项目） | 本地开发 | `autodl-tmp/NeuroBridge/` |

---

### 4.3 下载的数据集

| 数据集 | 来源 | 位置 | 大小 |
|--------|------|------|------|
| TVSD normMUA（猕猴视觉皮层 MUA 神经数据） | TVSD 官方 Git + datalad/git-annex 下载 | `autodl-tmp/TVSD_dataset/` | 2.4 GB |
| THINGS 图像（1854 类对象图像） | OSF（password: things4all） | `autodl-tmp/THINGS_images/` | 9.5 GB（含 zip） |
| pei_pandarinath_nlb_2021（MC Maze NLB 基线数据） | DANDI Archive（via brainsets prepare） | `autodl-tmp/datasets/processed/pei_pandarinath_nlb_2021/` | ~51 MB（processed 总共 23 MB） |

**TVSD 数据结构：**
- `TVSD_dataset/monkeyF/`、`TVSD_dataset/monkeyN/`
- 包含 `normMUA.mat`（时间平均后的 2D MUA 数据）
- 格式：`train_MUA [22248, 1024]`，`test_MUA [100, 1024]`

---

### 4.4 生成的嵌入数据

| 文件 | 内容 | 位置 | 大小 |
|------|------|------|------|
| `clip_train_monkeyF.npy` | THINGS 训练集 CLIP ViT-L-14 嵌入（22248×768） | `NeuroBridge/data/clip_embeddings/` | ~66 MB |
| `clip_test_monkeyF.npy` | THINGS 测试集 CLIP 嵌入（100×768） | `NeuroBridge/data/clip_embeddings/` | ~66 MB |

---

### 4.5 训练产生的 Checkpoints

| Checkpoint 目录 | 内容 | 最佳结果 |
|----------------|------|---------|
| `checkpoints/masking_pretrain_v1/` | Masking 预训练编码器（200 epochs） | MSE 0.212→0.092 |
| `checkpoints/clip_alignment_v1/` | CLIP 对齐 V1（无增强，100 epochs） | Test Top-5=82% |
| `checkpoints/clip_alignment_v2/` | CLIP 对齐 V2（含增强，early stop epoch 72） | Test Top-5=85%（n2i），89%（i2n） |
| `checkpoints/clip_alignment_v3_pretrained/` | CLIP 对齐 V3（预训练编码器 warmup） | Top-5=76%（不如随机初始化） |
| `checkpoints/clip_alignment_ITonly/` | 消融：仅 IT 脑区（320 电极） | Top-5=77% |
| `checkpoints/clip_alignment_V4only/` | 消融：仅 V4 脑区（192 电极） | Top-5=58% |
| `checkpoints/clip_alignment_V1only/` | 消融：仅 V1 脑区（512 电极） | Top-5=45% |
| `checkpoints/diffusion_adapter_v1/` | DiffusionAdapter（17.2M 参数，200 epochs） | — |

所有 checkpoint 目录均包含：`best_model.pt`、各 epoch checkpoint、`config.json`、`training_log.txt`

---

### 4.6 实验结果

| 结果目录 | 内容 |
|---------|------|
| `results/reconstruction_v2/` | 未训练 Adapter 的重建结果（all_metrics.json, retrieval_metrics.json） |
| `results/reconstruction_v3_trained/` | 已训练 Adapter 的完整评估结果（evaluation_metrics.json, retrieval_metrics.json, all_metrics.json） |

---

### 4.7 POYO 基线训练

**运行位置：** `autodl-tmp/torch_brain/examples/poyo/`
**训练命令：**
```bash
conda activate poyo
python train.py --config-name train_mc_maze_small.yaml \
  data_root=autodl-tmp/datasets/processed wandb.enable=false
```
**最终结果：** 1000 epochs，Test R²=0.836（日志保存于 `cc_todo/poyo_baseline_train.log`）

---

## 五、brainsets 配置

- 配置文件：`/root/.brainsets.yaml`
- raw 数据目录：`autodl-tmp/datasets/raw/`
- processed 数据目录：`autodl-tmp/datasets/processed/`

---

## 六、环境变量配置

| 变量 | 值 | 用途 |
|------|----|------|
| `PYTHONPATH` | `autodl-tmp/NeuroBridge` | 使 `neurobridge` 包可直接 import |
| `HF_ENDPOINT` | `https://hf-mirror.com` | HuggingFace 国内镜像（用于下载 SD 模型） |

---

## 七、当前 Pipeline 整体状态

```
猕猴 MUA 信号 (1024 电极)
    ↓ TVSDNormMUADataset（数据适配）
    ↓ NeuroBridgeEncoder (CaPOYO, 2.3M params)  ← 可加载 masking 预训练权重
    ↓ Cross-Attention Readout (K=8 queries)
    ↓ MLP Projector (768-dim)
    ↓ CLIP 语义空间对齐（InfoNCE 对比学习）
      最佳结果：Test n2i Top-5 = 85%
    ↓ DiffusionAdapter (17.2M params)
    ↓ Stable Diffusion 1.5 (DDIM)
    ↓ 重建图像
      当前 CLIP-sim=0.606，检索基线明显优于 SD 生成
```

---

## 八、待解决的关键问题

根据文档和实验结果，以下问题尚需改进：

1. **SD 图像生成质量差**：PixCorr=0.036，CLIP-ID Top-1 仅 1%，远低于检索基线（28%）
2. **预训练效果反而下降**：Masking 预训练编码器（76%）< 随机初始化（85%），需要研究预训练任务与下游任务的对齐
3. **模型规模受限**：当前 2.3M 参数的编码器相对较小，可能限制表达能力
4. **单猴数据**：目前仅使用 monkeyF 数据，未跨猴验证泛化性
